---
title: "Practical Machine Learning Project"
output: html_document
---

## Introduction

The overall goal of this document is to describe the analysis that was conducted for Coursera course "Practical Machine Learning"  project. The brief summary of the project is :
In this project, we use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. Each participant were asked to perform barbell lifts correctly and incorrectly in 5 different ways.The goal of your project is to predict the manner in which they did the exercise, as it is rarely quantified on how well a participant does the activity than how regularly they do it.The data for this project come from this source: http://groupware.les.inf.puc-rio.br/har. 

```{r}
# Necessary libraries
library(caret)
library(rattle)
library(rpart)
library(randomForest)

set.seed(12345)
```

## Getting the data

```{r}
Urltrain <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
Urltest <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
training <- read.csv(url(Urltrain), na.strings=c("NA","#DIV/0!",""))
testing <- read.csv(url(Urltest), na.strings=c("NA","#DIV/0!",""))

# Divide the training data set into two data sets, 60% for training, 40% for testing:
inTrain <- createDataPartition(y=training$classe, p=0.6, list=FALSE)
train_60train <- training[inTrain, ] 
train_40test <- training[-inTrain, ]
```

### Cleaning the data

This is done using three-step process.

```{r}

# Cleaning NearZeroVariance Variables
NZVvars <- names(train_60train) %in% c("new_window", "kurtosis_roll_belt", "kurtosis_picth_belt",
"kurtosis_yaw_belt", "skewness_roll_belt", "skewness_roll_belt.1", "skewness_yaw_belt",
"max_yaw_belt", "min_yaw_belt", "amplitude_yaw_belt", "avg_roll_arm", "stddev_roll_arm",
"var_roll_arm", "avg_pitch_arm", "stddev_pitch_arm", "var_pitch_arm", "avg_yaw_arm",
"stddev_yaw_arm", "var_yaw_arm", "kurtosis_roll_arm", "kurtosis_picth_arm",
"kurtosis_yaw_arm", "skewness_roll_arm", "skewness_pitch_arm", "skewness_yaw_arm",
"max_roll_arm", "min_roll_arm", "min_pitch_arm", "amplitude_roll_arm", "amplitude_pitch_arm",
"kurtosis_roll_dumbbell", "kurtosis_picth_dumbbell", "kurtosis_yaw_dumbbell", "skewness_roll_dumbbell",
"skewness_pitch_dumbbell", "skewness_yaw_dumbbell", "max_yaw_dumbbell", "min_yaw_dumbbell",
"amplitude_yaw_dumbbell", "kurtosis_roll_forearm", "kurtosis_picth_forearm", "kurtosis_yaw_forearm",
"skewness_roll_forearm", "skewness_pitch_forearm", "skewness_yaw_forearm", "max_roll_forearm",
"max_yaw_forearm", "min_roll_forearm", "min_yaw_forearm", "amplitude_roll_forearm",
"amplitude_yaw_forearm", "avg_roll_forearm", "stddev_roll_forearm", "var_roll_forearm",
"avg_pitch_forearm", "stddev_pitch_forearm", "var_pitch_forearm", "avg_yaw_forearm",
"stddev_yaw_forearm", "var_yaw_forearm")

train_60train <- train_60train[!NZVvars]
dim(train_60train)

# Removing first ID variable so that it does not interfere with ML Algorithms
train_60train <- train_60train[c(-1)]

# Cleaning Variables with too many NAs.
trainingV3 <- train_60train 
for(i in 1:length(train_60train)) 
{ 
    if( sum( is.na( train_60train[, i] ) ) /nrow(train_60train) >= .6 ) 
    { 
    	for(j in 1:length(trainingV3)) 
        {
			if( length( grep(names(train_60train[i]), names(trainingV3)[j]) ) ==1)  
            { 
				trainingV3 <- trainingV3[ , -j] 
			}	
		} 
	}
}
dim(trainingV3)
train_60train <- trainingV3

# Clean up the other data sets using the three-step process. 
clean1 <- colnames(train_60train)
clean2 <- colnames(train_60train[, -58])
train_40test <- train_40test[clean1]
testing <- testing[clean2]
dim(train_40test)
dim(testing)

# Coerce the testing and training data into the same type.
for (i in 1:length(testing) ) {
        for(j in 1:length(train_60train)) {
		if( length( grep(names(train_60train[i]), names(testing)[j]) ) ==1)  {
			class(testing[j]) <- class(train_60train[i])
		}      
	}      
}
testing <- rbind(train_60train[2, -58] , testing) 
testing <- testing[-1,]
```

## Using ML algorithms for prediction: Random Forests
```{r}
modFitB1 <- randomForest(classe ~. , data=train_60train)
```

## Prediction of 40% training dataset
```{r}
predictionsB1 <- predict(modFitB1, train_40test, type = "class")
```

## Confusion Matrix to test results:
```{r}
confusionMatrix(predictionsB1, train_40test$classe)
```

## Predict using random Forests on testing sample of 20 
```{r}
predictionsB2 <- predict(modFitB1, testing, type = "class")
```

## Function to generate files with predictions to submit for assignment:
```{r}
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}
pml_write_files(predictionsB2)
```